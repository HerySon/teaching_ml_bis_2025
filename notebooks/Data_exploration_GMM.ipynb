{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse de Clustering avec GMM sur OpenFoodFacts\n",
    "### Table des matières\n",
    "1. [Chargement et préparation des données](#1),\n",
    "2. [Prétraitement et nettoyage](#2),\n",
    "3. [Sélection des features pour le clustering](#3),\n",
    "4. [Préparation pour GMM](#4),\n",
    "5. [Modélisation GMM](#5),\n",
    "6. [Analyse des clusters](#6),\n",
    "7. [Visualisation des résultats](#7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement et préparation des données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-02-19T09:28:54.221631Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from scripts.features.processing import (\n",
    "    process_numeric_columns,\n",
    "    process_categorical_columns,\n",
    "    detect_ordinal_nature\n",
    ")\n",
    "from scripts.features.selection import (\n",
    "    analyze_and_select_features,\n",
    "    analyze_feature_importance,\n",
    "    select_relevant_features\n",
    ")\n",
    "from scripts.data.analysis import analyze_data_quality\n",
    "\n",
    "# Chargement des données avec limitation à 300000 lignes\n",
    "from scripts.data_handling.loader import load_data\n",
    "df = pd.read_csv('../data/en.openfoodfacts.org.products.csv', \n",
    "                 sep='\\t',\n",
    "                 encoding='utf-8',\n",
    "                 low_memory=False,\n",
    "                 on_bad_lines='skip',\n",
    "                 nrows=300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres de prétraitement\n",
    "MAX_CATEGORIES = 30  # Nombre maximum de catégories pour les variables catégorielles\n",
    "MIN_UNIQUE_RATIO = 0.01  # Ratio minimum de valeurs uniques pour les variables numériques\n",
    "MISSING_THRESHOLD = 0.5  # Seuil maximum de valeurs manquantes acceptables\n",
    "\n",
    "# Analyse initiale de la qualité des données\n",
    "print(\"1. Analyse de la qualité des données initiales :\")\n",
    "quality_report = analyze_data_quality(df)\n",
    "print(f\"\\nNombre de lignes dupliquées : {quality_report['duplicates']}\")\n",
    "print(\"\\nDistribution des valeurs manquantes :\")\n",
    "display(quality_report['missing_values'])\n",
    "\n",
    "# Prétraitement et sélection automatique des features\n",
    "print(\"\\n2. Détection et prétraitement automatique des variables :\")\n",
    "df_processed, feature_info = analyze_and_select_features(\n",
    "    df,\n",
    "    max_categories=MAX_CATEGORIES,\n",
    "    min_unique_ratio=MIN_UNIQUE_RATIO,\n",
    "    missing_threshold=MISSING_THRESHOLD\n",
    ")\n",
    "\n",
    "# Affichage des résultats du prétraitement\n",
    "print(\"\\n3. Résumé des variables détectées :\")\n",
    "print(f\"Variables numériques : {len(feature_info['feature_types']['numeric'])}\")\n",
    "print(f\"Variables ordinales : {len(feature_info['feature_types']['ordinal'])}\")\n",
    "print(f\"Variables nominales : {len(feature_info['feature_types']['nominal'])}\")\n",
    "\n",
    "# Affichage des optimisations de types de données\n",
    "if feature_info['downcasted_columns']:\n",
    "    print(\"\\n4. Optimisations des types de données :\")\n",
    "    for col, old_type, new_type in feature_info['downcasted_columns']:\n",
    "        print(f\"- {col}: {old_type} → {new_type}\")\n",
    "\n",
    "# Affichage des colonnes filtrées\n",
    "if feature_info['dropped_columns']:\n",
    "    print(\"\\n5. Colonnes filtrées :\")\n",
    "    for col, reason in feature_info['dropped_columns']:\n",
    "        print(f\"- {col} (raison: {reason})\")\n",
    "\n",
    "# Analyse des corrélations entre variables numériques\n",
    "print(\"\\n6. Analyse des corrélations entre variables numériques :\")\n",
    "correlations = analyze_correlations(df_processed, threshold=0.7, plot=True)\n",
    "if correlations['strong_correlations']:\n",
    "    print(\"\\nPaires de variables fortement corrélées :\")\n",
    "    for corr in correlations['strong_correlations']:\n",
    "        print(f\"- {corr['var1']} - {corr['var2']}: {corr['correlation']:.2f}\")\n",
    "\n",
    "# Sauvegarde du DataFrame prétraité\n",
    "df = df_processed.copy()\n",
    "print(f\"\\nDimensions finales du DataFrame : {df.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
